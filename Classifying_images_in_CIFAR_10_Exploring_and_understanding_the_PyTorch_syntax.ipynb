{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyO6PC/WglBRSdpyyBY4i9gA",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Albaraazain/Classifying-images-in-CIFAR-10---Exploring-and-understanding-the-PyTorch-syntax/blob/main/Classifying_images_in_CIFAR_10_Exploring_and_understanding_the_PyTorch_syntax.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The ' torchvision ' package consists of popular datasets, model architectures, and common image transformations for computer vision.\n"
      ],
      "metadata": {
        "id": "47Ei4YZSD7zi"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h4P5n3VWDFuv",
        "outputId": "3ecb708a-658a-4ab4-cea7-6da43fc62ba7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.1.0+cu121)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (0.16.0+cu121)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.13.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch) (4.9.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.3)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2023.6.0)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch) (2.1.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision) (1.23.5)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torchvision) (2.31.0)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision) (9.4.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision) (2024.2.2)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install torch torchvision"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torchvision import datasets, transforms"
      ],
      "metadata": {
        "id": "dM3dan20KkHe"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Prepare the dataset\n",
        "preparing the dataset involves several steps:\n",
        "* obtaining the dataset\n",
        "* transforming the data into a form suitable to use in neural networks (resizing images to a consistent size, normalizing pixel values, and applying other preprocessing steps such as data augmentation)\n",
        "* loading a data in a way to make it easier to iterate over during training and testing. after transforming the data. Data needs to be loaded into memory in a way to facilitate iteration during both training and testing. in pytorch this is done using DataLoader class, which allows for easy batching of data, shuffling, and parellizing data loading to speed up training. The dataloader also helps in handling large datasets that may not fit into memory by loading batches of data as needed during training.\n"
      ],
      "metadata": {
        "id": "mLwEFCMKENY7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Obtaining the dataset\n",
        "The CIFAR-10 dataset is a collection of 60,000 32x32 color images in 10 classes, with 6,000 images per class. It is divided into 50,000 training images and 10,000 testing images. PyTorch's torchvision package provides a convenient way to download and load this dataset through the datasets.CIFAR10 class.\n"
      ],
      "metadata": {
        "id": "hjtHe-36I6N8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Transforming the data\n",
        "Before feeding the image into a neural network, they often need to be transformed to make them suitable for training. Common transformation includes:\n",
        "* **Normalization**: Adjusting the pixel values so that they have a mean of 0 and a standard deviation of 1, helps the network learn more efficiently. the normalization parameters (mean, std) are chosen based on the dataset. For CIFAR-10, since the images are in RGB fromat,  we provide a mean and standard deviation for each of the three channels (Red, Green, Blue).\n",
        "* ToTensor: Converts a PIL image or a Numpy array into a Pytorch tensor. This is also necessary because pytorch models expect inputs to be tensors.\n",
        "\n",
        "the transform.compose function is used to chain tgthr these transformations.\n",
        "\n",
        "In this example\n",
        "* we first convert the images to tensors\n",
        "* then the normalize them:\n"
      ],
      "metadata": {
        "id": "qg4EaHOaJGlr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
        "])"
      ],
      "metadata": {
        "id": "qvK4bLeSEA-u"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "transforms.ToTensor(): This transformation converts the input image, which could be in various formats such as PIL Image or numpy array, into a PyTorch tensor. PyTorch tensors are the primary data structure used for representing data in PyTorch. This transformation essentially converts the image data into a format that can be directly consumed by a PyTorch neural network.\n",
        "\n",
        "transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)): This transformation normalizes the tensor by subtracting the mean and dividing by the standard deviation along each channel of the image. The parameters passed to Normalize() represent the mean and standard deviation values for each channel in the dataset. In this case, (0.5, 0.5, 0.5) represents the mean values for the red, green, and blue channels, respectively, while (0.5, 0.5, 0.5) represents the standard deviation values for the same channels. By applying this normalization, the pixel values in the images are scaled to have zero mean and unit variance, which can help improve convergence during training and make the optimization process more stable."
      ],
      "metadata": {
        "id": "I2cTcnceLey3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Loading the Data\n",
        "* After defining the transformation, we can load the CIFAR-10 dataset and apply these trasnfomations.\n",
        "* We use the datasets.CIFAR-10 class to download the datasets and apply the trasnformations.\n",
        "* We then create a DataLoader instances for both training and testing sets.\n",
        "\n",
        "---\n",
        "\n",
        "* DataLoader: This is a pytorch class that provides batches of images from the dataset, shuffles the data, and provide other utilities like parallelizing the data loading using multiple workers. batch_size determines how many images are in each batch. smaller batch sizes require less memory and can make the network update its weights more frequently, but may take longer to train."
      ],
      "metadata": {
        "id": "ykiQn7NwMNg5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Downloading and load the training data\n",
        "trainset = datasets.CIFAR10('~/.pytorch/CIFAR_10_data/', download=True, train=True, transform=transforms)\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=64, shuffle=True)\n",
        "\n",
        "# Downloading and load the test data\n",
        "testset = datasets.CIFAR10('~pytorch/CIFAR_10_data/', download=True, train=True, transforms=transforms)\n",
        "testloader = torch.utils.data.dataloader(testset, batch_size=64, shuffle=True)"
      ],
      "metadata": {
        "id": "dXl1A2OSEA6q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**next step** after preparing the dataset is to define the neural network that will be used for image classification. in this context, we're working with\n",
        "* the CIFAR-10 dataset, which includes images that needs to be classified into one of ten categories\n",
        "we will need to define the network we will need for the CIFAR-10 dataset:\n",
        "\n",
        "---\n",
        "\n",
        " 1. Convulution Layers: These layers perform the convolution operation, passing the input image through several convolution filters to detect features such as edges, textures, etc. For CIFAR-10: we start with a convulution layer that takes 3 input channels (RGB) and produces 6 output channels with a 5x5 kernel size, followed by another convolution layer that increases the depth from 6 to 16 while keeping the same kernel size\n"
      ],
      "metadata": {
        "id": "auMIAfYQQbH6"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "3D1PbhTDEA3z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "hD0o2YY9EA1a"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}